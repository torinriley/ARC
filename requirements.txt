torch>=2.1.0
transformers>=4.36.0
datasets>=2.15.0
accelerate>=0.25.0
huggingface_hub>=0.19.4
wandb>=0.16.0
deepspeed>=0.12.0
flash-attn>=2.3.0
einops>=0.7.0
sentencepiece>=0.1.99
tokenizers>=0.15.0
zstandard>=0.22.0
